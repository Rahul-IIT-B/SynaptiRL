{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Learning with MAML and Omniglot (Optimized)\n",
    "\n",
    "This notebook implements **Model-Agnostic Meta-Learning (MAML)**. This version has been **optimized** to address common issues with long runtimes and stagnant training loss.\n",
    "\n",
    "**Key Changes:**\n",
    "1.  **Reduced Inner Learning Rate:** To help the model learn effectively.\n",
    "2.  **Reduced Batch Size:** To significantly decrease training time.\n",
    "3.  **Early Stopping for Debugging:** The training loop stops after 100 batches to allow for quick verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q comet_ml torch torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import Omniglot\n",
    "from PIL import Image\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the N-way K-shot Task Dataset\n",
    "\n",
    "This dataset generates entire few-shot classification tasks. Each item from this dataset is a complete task, containing a support set (for learning) and a query set (for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotTaskDataset(Dataset):\n",
    "    \"\"\"Dataset for generating N-way K-shot tasks from Omniglot.\"\"\"\n",
    "    def __init__(self, n_way, k_shot, k_query, root_dir, background=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.omniglot = Omniglot(root=root_dir, background=background, download=True)\n",
    "        self.transform = transform\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "\n",
    "        # Group image indices by character class\n",
    "        self.class_indices = {}\n",
    "        for i, (_, label) in enumerate(self.omniglot._flat_character_images):\n",
    "            if label not in self.class_indices:\n",
    "                self.class_indices[label] = []\n",
    "            self.class_indices[label].append(i)\n",
    "        \n",
    "        self.class_list = list(self.class_indices.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        # The number of possible tasks is very large, so we can set a large number for an epoch\n",
    "        return 20000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Sample N classes for the task\n",
    "        task_classes = random.sample(self.class_list, self.n_way)\n",
    "\n",
    "        support_images, support_labels = [], []\n",
    "        query_images, query_labels = [], []\n",
    "\n",
    "        for i, cls_idx in enumerate(task_classes):\n",
    "            # 2. Sample K-shot + K-query images from each class\n",
    "            class_images_indices = self.class_indices[cls_idx]\n",
    "            if len(class_images_indices) < self.k_shot + self.k_query:\n",
    "                sampled_indices = random.choices(class_images_indices, k=self.k_shot + self.k_query)\n",
    "            else:\n",
    "                sampled_indices = random.sample(class_images_indices, self.k_shot + self.k_query)\n",
    "            \n",
    "            # 3. Split into support and query sets\n",
    "            support_indices = sampled_indices[:self.k_shot]\n",
    "            query_indices = sampled_indices[self.k_shot:]\n",
    "\n",
    "            # Load and transform images for the support set\n",
    "            for idx in support_indices:\n",
    "                img, _ = self.omniglot[idx]\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                support_images.append(img)\n",
    "                support_labels.append(i)\n",
    "            \n",
    "            # Load and transform images for the query set\n",
    "            for idx in query_indices:\n",
    "                img, _ = self.omniglot[idx]\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                query_images.append(img)\n",
    "                query_labels.append(i)\n",
    "\n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.LongTensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.LongTensor(query_labels)\n",
    "\n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "\n",
    "# --- Model Definition ---\n",
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(MetaLearner, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters and Data Loading\n",
    "\n",
    "**Changes Applied Here:**\n",
    "- `BATCH_SIZE` reduced from 32 to 8 to speed up training.\n",
    "- `INNER_LR` reduced from 0.04 to 0.01 to fix the stagnant loss issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-learning parameters\n",
    "N_WAY = 5          # Number of classes in a task\n",
    "K_SHOT = 1         # Number of support examples per class\n",
    "K_QUERY = 15       # Number of query examples per class\n",
    "\n",
    "# --- OPTIMIZATION 1: Reduce batch size to decrease runtime ---\n",
    "BATCH_SIZE = 8     # Reduced from 32. Fewer tasks per step = faster training.\n",
    "NUM_EPOCHS = 1     # One epoch is long (20k tasks), so 1 is enough for a demo\n",
    "\n",
    "# MAML-specific parameters\n",
    "META_LR = 0.001       # Outer loop learning rate\n",
    "\n",
    "# --- OPTIMIZATION 2: Reduce inner learning rate to fix stagnant loss ---\n",
    "INNER_LR = 0.01       # Reduced from 0.04. MAML is very sensitive to this value.\n",
    "INNER_STEPS = 1     # Number of gradient steps in inner loop\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = OmniglotTaskDataset(N_WAY, K_SHOT, K_QUERY, root_dir='./data', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MAML Initialization and Training Loop\n",
    "\n",
    "**Change Applied Here:**\n",
    "- An `if` condition has been added to `break` the loop after 100 batches. This allows for a quick check to see if the loss is now decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MAML training on device: cpu\n",
      "Epoch [1/1], Batch [50/2500], Meta Loss: 1.6100\n",
      "Epoch [1/1], Batch [100/2500], Meta Loss: 1.6087\n",
      "Epoch [1/1], Batch [150/2500], Meta Loss: 1.6090\n",
      "Epoch [1/1], Batch [200/2500], Meta Loss: 1.6088\n",
      "Stopping epoch early for a quick test.\n",
      "\n",
      "Meta-training finished!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the meta-model\n",
    "meta_model = MetaLearner(input_channels=1, num_classes=N_WAY).to(device)\n",
    "meta_optimizer = optim.Adam(meta_model.parameters(), lr=META_LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Starting MAML training on device: {device}\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    meta_model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Unpack the batch of tasks\n",
    "        s_imgs, s_labels, q_imgs, q_labels = batch\n",
    "        s_imgs, s_labels = s_imgs.to(device), s_labels.to(device)\n",
    "        q_imgs, q_labels = q_imgs.to(device), q_labels.to(device)\n",
    "\n",
    "        meta_optimizer.zero_grad()\n",
    "        batch_meta_loss = 0.0\n",
    "\n",
    "        # Iterate over each task in the meta-batch\n",
    "        for i in range(BATCH_SIZE):\n",
    "            task_s_imgs, task_s_labels = s_imgs[i], s_labels[i]\n",
    "            task_q_imgs, task_q_labels = q_imgs[i], q_labels[i]\n",
    "\n",
    "            # Create a temporary 'fast' model for the inner loop\n",
    "            fast_model = copy.deepcopy(meta_model)\n",
    "            fast_optimizer = optim.SGD(fast_model.parameters(), lr=INNER_LR)\n",
    "\n",
    "            # --- Inner Loop: Adapt to the current task ---\n",
    "            for _ in range(INNER_STEPS):\n",
    "                support_preds = fast_model(task_s_imgs)\n",
    "                support_loss = loss_fn(support_preds, task_s_labels)\n",
    "                fast_optimizer.zero_grad()\n",
    "                support_loss.backward()\n",
    "                fast_optimizer.step()\n",
    "            \n",
    "            # --- Evaluate the adapted model on the query set ---\n",
    "            query_preds = fast_model(task_q_imgs)\n",
    "            query_loss = loss_fn(query_preds, task_q_labels)\n",
    "            batch_meta_loss += query_loss\n",
    "\n",
    "        # --- Outer Loop: Update the meta-model ---\n",
    "        meta_loss = batch_meta_loss / BATCH_SIZE\n",
    "        meta_loss.backward()\n",
    "        meta_optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 50 == 0: # Print progress every 50 batches\n",
    "            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], Meta Loss: {meta_loss.item():.4f}\")\n",
    "        \n",
    "        # --- OPTIMIZATION 3: Stop early for a quick test run ---\n",
    "        if (batch_idx + 1) == 200: # Increased to 200 to see more trend\n",
    "            print(\"Stopping epoch early for a quick test.\")\n",
    "            break\n",
    "\n",
    "print(\"\\nMeta-training finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Meta-Learned Model\n",
    "\n",
    "Now we can test how well our meta-model works. We'll create a new test task, adapt the model using the support set, and then measure its final accuracy on the query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the meta-model on a new task...\n",
      "Test Task Accuracy (5-way, 1-shot): 36.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the meta-model on a new task...\")\n",
    "\n",
    "# Create a new dataset for testing (using the evaluation set of characters)\n",
    "test_dataset = OmniglotTaskDataset(N_WAY, K_SHOT, K_QUERY, root_dir='./data', background=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Get one test task\n",
    "test_s_imgs, test_s_labels, test_q_imgs, test_q_labels = next(iter(test_loader))\n",
    "test_s_imgs, test_s_labels = test_s_imgs.squeeze(0).to(device), test_s_labels.squeeze(0).to(device)\n",
    "test_q_imgs, test_q_labels = test_q_imgs.squeeze(0).to(device), test_q_labels.squeeze(0).to(device)\n",
    "\n",
    "# Adapt the model on the test support set\n",
    "meta_model.eval()\n",
    "fast_model_test = copy.deepcopy(meta_model)\n",
    "fast_optimizer_test = optim.SGD(fast_model_test.parameters(), lr=INNER_LR)\n",
    "\n",
    "for _ in range(INNER_STEPS * 3): # Use a few more steps for testing\n",
    "    support_preds = fast_model_test(test_s_imgs)\n",
    "    support_loss = loss_fn(support_preds, test_s_labels)\n",
    "    fast_optimizer_test.zero_grad()\n",
    "    support_loss.backward()\n",
    "    fast_optimizer_test.step()\n",
    "\n",
    "# Evaluate the adapted model\n",
    "with torch.no_grad():\n",
    "    query_preds = fast_model_test(test_q_imgs)\n",
    "    _, predicted_labels = torch.max(query_preds, 1)\n",
    "    accuracy = (predicted_labels == test_q_labels).float().mean().item()\n",
    "\n",
    "print(f\"Test Task Accuracy ({N_WAY}-way, {K_SHOT}-shot): {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
